{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Set the working directory to the root of the Git repository\n",
    "current_dir = os.getcwd()\n",
    "git_root = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=current_dir)\n",
    "git_root = git_root.decode(\"utf-8\").strip()\n",
    "os.chdir(git_root)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import tqdm\n",
    "from colorama import Fore, Style\n",
    "import math\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>tmp</th>\n",
       "      <th>hum</th>\n",
       "      <th>CO2</th>\n",
       "      <th>VOC</th>\n",
       "      <th>room</th>\n",
       "      <th>floor</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "      <th>outside_tmp</th>\n",
       "      <th>outside_hum</th>\n",
       "      <th>outside_rain</th>\n",
       "      <th>outside_snowfall</th>\n",
       "      <th>outside_wind_speed</th>\n",
       "      <th>outside_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-06 00:12:02</td>\n",
       "      <td>20.44</td>\n",
       "      <td>25.06</td>\n",
       "      <td>432</td>\n",
       "      <td>768</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>spring</td>\n",
       "      <td>0.489</td>\n",
       "      <td>93.343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.091</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-06 00:27:08</td>\n",
       "      <td>20.46</td>\n",
       "      <td>24.99</td>\n",
       "      <td>428</td>\n",
       "      <td>758</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>spring</td>\n",
       "      <td>0.489</td>\n",
       "      <td>93.343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.091</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-06 00:42:15</td>\n",
       "      <td>20.44</td>\n",
       "      <td>25.06</td>\n",
       "      <td>429</td>\n",
       "      <td>758</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>spring</td>\n",
       "      <td>0.489</td>\n",
       "      <td>93.343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.091</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time    tmp    hum  CO2  VOC room  floor        date  month  \\\n",
       "0 2023-03-06 00:12:02  20.44  25.06  432  768  002      0  2023-03-06      3   \n",
       "1 2023-03-06 00:27:08  20.46  24.99  428  758  002      0  2023-03-06      3   \n",
       "2 2023-03-06 00:42:15  20.44  25.06  429  758  002      0  2023-03-06      3   \n",
       "\n",
       "   hour  day_of_week  is_weekend  season  outside_tmp  outside_hum  \\\n",
       "0     0            0       False  spring        0.489       93.343   \n",
       "1     0            0       False  spring        0.489       93.343   \n",
       "2     0            0       False  spring        0.489       93.343   \n",
       "\n",
       "   outside_rain  outside_snowfall  outside_wind_speed  outside_pressure  \n",
       "0           0.0               0.0               7.091            1012.0  \n",
       "1           0.0               0.0               7.091            1012.0  \n",
       "2           0.0               0.0               7.091            1012.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = os.path.join(cwd, \"data\", \"processed\", \"data_building_n.parquet\")\n",
    "df = pd.read_parquet(fpath)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Engineering (for the NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'tmp', 'hum', 'CO2', 'VOC', 'room', 'floor', 'date',\n",
       "       'month', 'hour', 'day_of_week', 'is_weekend', 'season', 'outside_tmp',\n",
       "       'outside_hum', 'outside_rain', 'outside_snowfall', 'outside_wind_speed',\n",
       "       'outside_pressure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time projection\n",
    "Converting periodic time series data into a format that can be used by a neural network is a bit tricky. The main problem is that the time series is periodic, so the network should be able to understand that the last value is close to the first value.\n",
    "We therefore project the time series data into a higher dimensional space, where the periodicity is more easily understood. This is done by using the sin and cos functions to encode the time of the year and the time of the day.\n",
    "See this article for more information: https://towardsdatascience.com/how-to-encode-periodic-time-features-7640d9b21332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_date_to_unit_circle(input_date: date):\n",
    "    year = input_date.year\n",
    "    passed_days = (input_date - date(year, 1, 1)).days + 1\n",
    "    nr_of_days_per_year = 366 if calendar.isleap(year) else 365\n",
    "    position_within_year = passed_days / nr_of_days_per_year\n",
    "    alpha = position_within_year * math.pi * 2\n",
    "    year_circle_x = (math.sin(alpha) + 1) / 2\n",
    "    year_circle_y = (math.cos(alpha) + 1) / 2\n",
    "    return year_circle_x, year_circle_y\n",
    "\n",
    "def project_day_of_week_to_unit_circle(input_day_of_week: int):\n",
    "    alpha = input_day_of_week / 7 * math.pi * 2\n",
    "    day_of_week_circle_x = (math.sin(alpha) + 1) / 2\n",
    "    day_of_week_circle_y = (math.cos(alpha) + 1) / 2\n",
    "    return day_of_week_circle_x, day_of_week_circle_y\n",
    "\n",
    "# Project the date to a unit circle (year)\n",
    "df['date_circle_x'], df['date_circle_y'] = zip(*df['date'].apply(project_date_to_unit_circle))\n",
    "\n",
    "# Project the day_of_week to a unit circle (week)\n",
    "df['day_of_week_circle_x'], df['day_of_week_circle_y'] = zip(*df['day_of_week'].apply(project_day_of_week_to_unit_circle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- One hot encoding ----------------------------------\n",
    "# Season\n",
    "df = pd.get_dummies(df, columns=['season'], prefix='season')\n",
    "\n",
    "# Floor\n",
    "df = pd.get_dummies(df, columns=['floor'], prefix='floor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Resampling ----------------------------------------\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df.set_index('date_time', inplace=True)\n",
    "\n",
    "df_daily = df.resample('D').mean().dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_daily[[\n",
    "    'tmp', 'hum', 'CO2', 'VOC', 'outside_tmp', 'outside_hum', 'outside_rain',\n",
    "    'outside_snowfall', 'outside_wind_speed', 'outside_pressure',\n",
    "    'date_circle_x', 'date_circle_y', 'day_of_week_circle_x',\n",
    "    'day_of_week_circle_y', 'season_autumn', 'season_spring',\n",
    "    'season_summer', 'season_winter', 'floor_0', 'floor_1', 'floor_2',\n",
    "    'floor_3'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hum</th>\n",
       "      <th>CO2</th>\n",
       "      <th>VOC</th>\n",
       "      <th>outside_tmp</th>\n",
       "      <th>outside_hum</th>\n",
       "      <th>outside_rain</th>\n",
       "      <th>outside_snowfall</th>\n",
       "      <th>outside_wind_speed</th>\n",
       "      <th>outside_pressure</th>\n",
       "      <th>date_circle_x</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_circle_y</th>\n",
       "      <th>season_autumn</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>floor_0</th>\n",
       "      <th>floor_1</th>\n",
       "      <th>floor_2</th>\n",
       "      <th>floor_3</th>\n",
       "      <th>tmp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-18</th>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.385416</td>\n",
       "      <td>0.485801</td>\n",
       "      <td>0.750007</td>\n",
       "      <td>0.344018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245064</td>\n",
       "      <td>0.633750</td>\n",
       "      <td>0.846859</td>\n",
       "      <td>...</td>\n",
       "      <td>3.568959e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23</th>\n",
       "      <td>0.476494</td>\n",
       "      <td>0.339036</td>\n",
       "      <td>0.297645</td>\n",
       "      <td>0.718637</td>\n",
       "      <td>0.499877</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299324</td>\n",
       "      <td>0.300974</td>\n",
       "      <td>0.814528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-24</th>\n",
       "      <td>0.500382</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.112113</td>\n",
       "      <td>0.577939</td>\n",
       "      <td>0.417913</td>\n",
       "      <td>0.035806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639309</td>\n",
       "      <td>0.401301</td>\n",
       "      <td>0.807774</td>\n",
       "      <td>...</td>\n",
       "      <td>8.019377e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>0.309725</td>\n",
       "      <td>0.105410</td>\n",
       "      <td>0.197073</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.285711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460466</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.800928</td>\n",
       "      <td>...</td>\n",
       "      <td>3.568959e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>0.436637</td>\n",
       "      <td>0.106785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>0.560812</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704533</td>\n",
       "      <td>0.652704</td>\n",
       "      <td>0.786971</td>\n",
       "      <td>...</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hum       CO2       VOC  outside_tmp  outside_hum  \\\n",
       "date_time                                                            \n",
       "2022-05-18  0.469027  0.385416  0.485801     0.750007     0.344018   \n",
       "2022-05-23  0.476494  0.339036  0.297645     0.718637     0.499877   \n",
       "2022-05-24  0.500382  0.120409  0.112113     0.577939     0.417913   \n",
       "2022-05-25  0.309725  0.105410  0.197073     0.612500     0.285711   \n",
       "2022-05-27  0.436637  0.106785  1.000000     0.546858     0.560812   \n",
       "\n",
       "            outside_rain  outside_snowfall  outside_wind_speed  \\\n",
       "date_time                                                        \n",
       "2022-05-18      0.000000               0.0            0.245064   \n",
       "2022-05-23      0.011821               0.0            0.299324   \n",
       "2022-05-24      0.035806               0.0            0.639309   \n",
       "2022-05-25      0.000000               0.0            0.460466   \n",
       "2022-05-27      0.008228               0.0            0.704533   \n",
       "\n",
       "            outside_pressure  date_circle_x  ...  day_of_week_circle_y  \\\n",
       "date_time                                    ...                         \n",
       "2022-05-18          0.633750       0.846859  ...          3.568959e-01   \n",
       "2022-05-23          0.300974       0.814528  ...          1.000000e+00   \n",
       "2022-05-24          0.401301       0.807774  ...          8.019377e-01   \n",
       "2022-05-25          0.549952       0.800928  ...          3.568959e-01   \n",
       "2022-05-27          0.652704       0.786971  ...          6.938894e-18   \n",
       "\n",
       "            season_autumn  season_spring  season_summer  season_winter  \\\n",
       "date_time                                                                \n",
       "2022-05-18            0.0            1.0            0.0            0.0   \n",
       "2022-05-23            0.0            1.0            0.0            0.0   \n",
       "2022-05-24            0.0            1.0            0.0            0.0   \n",
       "2022-05-25            0.0            1.0            0.0            0.0   \n",
       "2022-05-27            0.0            1.0            0.0            0.0   \n",
       "\n",
       "            floor_0  floor_1  floor_2  floor_3       tmp  \n",
       "date_time                                                 \n",
       "2022-05-18      1.0      0.0      0.0      0.0  0.924290  \n",
       "2022-05-23      1.0      0.0      0.0      0.0  1.000000  \n",
       "2022-05-24      1.0      0.0      0.0      0.0  0.878087  \n",
       "2022-05-25      1.0      0.0      0.0      0.0  0.776042  \n",
       "2022-05-27      1.0      0.0      0.0      0.0  0.659750  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- Scaling -------------------------------------------\n",
    "# Initialize the scalers\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Prepare the features and target\n",
    "features = df_daily.drop(['tmp'], axis=1)\n",
    "target = df_daily['tmp'].values.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform the features\n",
    "scaled_features = scaler_X.fit_transform(features)\n",
    "scaled_target = scaler_y.fit_transform(target).flatten()\n",
    "\n",
    "# Create a new DataFrame with scaled features\n",
    "scaled_df_daily = pd.DataFrame(scaled_features, index=df_daily.index, columns=features.columns)\n",
    "scaled_df_daily['tmp'] = scaled_target\n",
    "\n",
    "scaled_df_daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 21]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "class DailySequenceDataset(Dataset):\n",
    "    def __init__(self, df_daily, window_size=4):\n",
    "        \"\"\"\n",
    "        Initializes the Dataset.\n",
    "\n",
    "        :param df_daily: DataFrame with daily resampled data.\n",
    "        :param window_size: Size of the time window for sequences in days.\n",
    "        \"\"\"\n",
    "        self.df_daily = df_daily\n",
    "        self.window_size = window_size\n",
    "        self.X, self.y = self.create_sequences()\n",
    "\n",
    "    def create_sequences(self):\n",
    "        \"\"\"\n",
    "        Creates sequences of consecutive days.\n",
    "\n",
    "        :return: Tuple (X, y) where X is the input matrix and y is the output vector.\n",
    "        \"\"\"\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "\n",
    "        # Iterate over the DataFrame to find sequences of consecutive days\n",
    "        for i in range(len(self.df_daily) - self.window_size + 1):\n",
    "            if all(self.df_daily.index[i + j] == self.df_daily.index[i] + pd.Timedelta(days=j) for j in range(self.window_size)):\n",
    "                # Extract the input matrix (window_size-1 consecutive days)\n",
    "                X = self.df_daily.iloc[i:i+self.window_size-1].drop(['tmp'], axis=1).values\n",
    "                # Extract the output matrix (the last day in the window)\n",
    "                y = self.df_daily.iloc[i+self.window_size-1]['tmp']\n",
    "                \n",
    "                # Append the matrices to the respective lists\n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        X_array = np.array(X_list)\n",
    "        y_array = np.array(y_list)\n",
    "\n",
    "        return X_array, y_array\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples.\n",
    "\n",
    "        :return: Number of samples.\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the sample at the given index.\n",
    "\n",
    "        :param idx: Index of the sample.\n",
    "        :return: Tuple (X, y) containing the input data and the target variable.\n",
    "        \"\"\"\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return X, y\n",
    "\n",
    "# Initialize the dataset with scaled data\n",
    "window_size = 4\n",
    "dataset = DailySequenceDataset(scaled_df_daily, window_size)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example of iterating over the DataLoader\n",
    "for batch in dataloader:\n",
    "    X_batch, y_batch = batch\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    break  # Just to demonstrate, remove this in actual usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "window_size = 4\n",
    "dataset = DailySequenceDataset(scaled_df_daily, window_size)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Model parameters\n",
    "input_size = scaled_features.shape[1]\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.1493, Test RMSE: 0.3864\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_actuals = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_dataloader:\n",
    "        outputs = model(X_batch)\n",
    "        test_predictions.append(outputs.squeeze().cpu().numpy())\n",
    "        test_actuals.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Flatten the lists\n",
    "test_predictions = np.concatenate(test_predictions)\n",
    "test_actuals = np.concatenate(test_actuals)\n",
    "\n",
    "# Inverse transform the predictions and actuals to original scale\n",
    "test_predictions = scaler_y.inverse_transform(test_predictions.reshape(-1, 1)).flatten()\n",
    "test_actuals = scaler_y.inverse_transform(test_actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate and print the MSE and RMSE for the test data\n",
    "test_mse = mean_squared_error(test_actuals, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(f'Test MSE: {test_mse:.4f}, Test RMSE: {test_rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20.910542, 20.555653, 21.304731, 20.472727, 20.41582 , 21.202549,\n",
       "        20.654362, 21.550238, 21.446922, 20.366251, 20.492321, 20.703049,\n",
       "        20.573921], dtype=float32),\n",
       " array([21.046564, 21.025482, 21.45443 , 20.78753 , 21.237274, 21.215248,\n",
       "        20.964836, 21.18085 , 20.966024, 20.783794, 20.681116, 21.174911,\n",
       "        20.664803], dtype=float32))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_actuals, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0700, RMSE: 0.2646\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_dataloader:\n",
    "        outputs = model(X_batch)\n",
    "        predictions.append(outputs.squeeze().cpu().numpy())\n",
    "        actuals.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Flatten the lists\n",
    "predictions = np.concatenate(predictions)\n",
    "actuals = np.concatenate(actuals)\n",
    "\n",
    "# Inverse transform the predictions and actuals to original scale\n",
    "predictions = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "actuals = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate and print the MSE and RMSE\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'MSE: {mse:.4f}, RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20.910542, 20.555653, 21.304731, 20.472727, 20.41582 , 21.202549,\n",
       "        20.654362, 21.550238, 21.446922, 20.366251, 20.492321, 20.703049,\n",
       "        20.573921], dtype=float32),\n",
       " array([20.938267, 20.684793, 21.226948, 20.544085, 20.820656, 21.13143 ,\n",
       "        20.704638, 21.144112, 20.732079, 20.51746 , 20.511965, 20.787432,\n",
       "        20.510687], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals, predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
